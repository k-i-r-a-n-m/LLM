{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88705927-8c6d-4af6-8e7a-038c614962d6",
   "metadata": {},
   "source": [
    "# RAG -- Using FAISS as Local VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8388d-5a89-4089-bf9c-8db15bd7607c",
   "metadata": {},
   "source": [
    "#### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b7a23e-17f1-41e9-b932-f21cd7a32fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the file's path\n",
    "\n",
    "# 1. using relative paths\n",
    "# script_dir = os.path.dirname(__file__)\n",
    "# file_path = os.path.join(script_dir, \"./data/ReAct-research-paper.pdf\")\n",
    "# index_path = os.path.join(script_dir,'./data/Faiss-index-react-paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d9c6a-ab9b-4327-9d16-a6482ee11306",
   "metadata": {},
   "source": [
    "## Ingesting data to the FAISS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee15c02-3d25-4ffc-8f40-7d85819f88a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 2273, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "#new imports for pdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# using abspath and extracting the file's path\n",
    "file_path = os.path.abspath(\"./data/ReAct-research-paper.pdf\")\n",
    "index_path = os.path.abspath('./data/Faiss-index-react-paper')\n",
    "\n",
    "# load the pdf document and split into LIST of docs(each doc contains a page's content) [page-0,page-1...page-n]\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "#Control the chunk size using text_splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000,chunk_overlap=30,separator='\\n')\n",
    "docs = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "\n",
    "# Create the vectors and keeps it in the RAM\n",
    "vectorstore = FAISS.from_documents(docs,embeddings)\n",
    "\n",
    "# To persist the Vector store --> store it in a file\n",
    "vectorstore.save_local(index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8b158-914e-4f6f-a9dc-5c0086eef5c5",
   "metadata": {},
   "source": [
    "## Constructing Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f4e1fe-3a91-4b4b-ba02-4dd7243496d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ReAct is a new approach that combines language and decision making capabilities to solve various tasks. It uses a large language model to interact with external sources and gather information, while also allowing for human-like reasoning and decision making. This makes it more effective and interpretable than other methods. ReAct is easy to design, works for different tasks, and shows strong performance and generalization. It can be represented with a simple diagram as follows:\n",
      "\n",
      "[Human thought] -> [ReAct] -> [External sources] -> [Task solution]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI , OpenAIEmbeddings , OpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain import hub\n",
    "\n",
    "#new imports for FAISS\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initial Setup\n",
    "llm = OpenAI(temperature=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "retrieval_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "index_path = os.path.abspath('./data/Faiss-index-react-paper')\n",
    "\n",
    "\n",
    "# Load the Locally stored VectorStore from the FAISS\n",
    "new_vectorstore = FAISS.load_local(index_path,embeddings,allow_dangerous_deserialization=True)\n",
    "\n",
    "# Create Document chain\n",
    "combine_doc_chain = create_stuff_documents_chain(llm,retrieval_prompt)\n",
    "\n",
    "# Crate retrieval chain\n",
    "retrieval_chain = create_retrieval_chain(retriever=vectorstore.as_retriever(),combine_docs_chain=combine_doc_chain)\n",
    "\n",
    "result = retrieval_chain.invoke({\"input\":'explain react in simple terms with simple diagram'})\n",
    "\n",
    "print(result['answer'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53be6b-426b-4c7c-b255-0557af3834f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
